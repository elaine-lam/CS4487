{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0025faa5",
   "metadata": {},
   "source": [
    "## Template of the Test Code\n",
    "The test code template is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13d3ac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "def test(model, test_dataset_path):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    test_dataset = data_loader(test_dataset_path)\n",
    "    \n",
    "    for img, label in test_dataset:\n",
    "        # Please make sure that the \"pred\" is binary result\n",
    "        output = model(img.unsqueeze(dim=0).to(device))\n",
    "        pred = np.argmax(output.detach().to('cpu'),axis=1).item()\n",
    "        \n",
    "        y_true.append(label)\n",
    "        y_pred.append(pred)\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    Accuracy = metrics.accuracy_score(y_true, y_pred)\n",
    "\n",
    "    return Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe38350",
   "metadata": {},
   "source": [
    "Please make sure that the final \"y_pred\" should be a binary array. This is because \"metrics.accuracy_score(y_true, y_pred)\" calculates the accuracy between two label indicator arrays. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da54eaf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.array([0, 0, 1, 1])\n",
    "y_true = np.array([0, 1, 0, 1])\n",
    "metrics.accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1554aa",
   "metadata": {},
   "source": [
    "## A demo of \"data_loader\" and \"model\"\n",
    "A demo of \"data_loader\" and \"model\" is shown below. You need to construct your own \"data_loader\" and \"model\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "240bb435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class data_loader(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        # Get Image File Names\n",
    "        real = os.path.join(data_dir, '0_real')  # directory of files\n",
    "        fake = os.path.join(data_dir, '1_fake')\n",
    "\n",
    "        file_names_real = os.listdir(real)  # get list of images in that directory\n",
    "        self.full_filenames_real = [os.path.join(real, f) for f in file_names_real]  # get the full path to images\n",
    "        file_names_fake = os.listdir(fake)  # get list of images in that directory\n",
    "        self.full_filenames_fake = [os.path.join(fake, f) for f in file_names_fake]  # get the full path to images\n",
    "        self.full_filenames = self.full_filenames_real + self.full_filenames_fake\n",
    "\n",
    "        self.labels_real = [0 for filename in file_names_real]\n",
    "        self.labels_fake = [1 for filename in file_names_fake]\n",
    "        self.labels = self.labels_real + self.labels_fake\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "                                            transforms.RandomResizedCrop(size=(64, 64)),\n",
    "                                            transforms.ToTensor(),\n",
    "                                            ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.full_filenames_real) + len(self.full_filenames_fake) # size of dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # open image, apply transforms and return with label\n",
    "        image = Image.open(self.full_filenames[idx])  # Open Image with PIL\n",
    "        image = self.transform(image) # Apply Specific Transformation to Image\n",
    "        return image, self.labels[idx]\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Neural Network\n",
    "class Network(nn.Module):\n",
    "    \n",
    "    # Network Initialisation\n",
    "    def __init__(self, params):\n",
    "        \n",
    "        super(Network, self).__init__()\n",
    "    \n",
    "        Cin,Hin,Win=params[\"shape_in\"]\n",
    "        init_f=params[\"initial_filters\"] \n",
    "        num_fc1=params[\"num_fc1\"]  \n",
    "        num_classes=params[\"num_classes\"] \n",
    "        self.dropout_rate=params[\"dropout_rate\"] \n",
    "        \n",
    "        # Convolution Layers\n",
    "        self.conv1 = nn.Conv2d(Cin, init_f, kernel_size=3)\n",
    "        h,w=findConv2dOutShape(Hin,Win,self.conv1)\n",
    "        self.conv2 = nn.Conv2d(init_f, 2*init_f, kernel_size=3)\n",
    "        h,w=findConv2dOutShape(h,w,self.conv2)\n",
    "        self.conv3 = nn.Conv2d(2*init_f, 4*init_f, kernel_size=3)\n",
    "        h,w=findConv2dOutShape(h,w,self.conv3)\n",
    "        self.conv4 = nn.Conv2d(4*init_f, 8*init_f, kernel_size=3)\n",
    "        h,w=findConv2dOutShape(h,w,self.conv4)\n",
    "        \n",
    "        # compute the flatten size\n",
    "        self.num_flatten=h*w*8*init_f\n",
    "        self.fc1 = nn.Linear(self.num_flatten, num_fc1)\n",
    "        self.fc2 = nn.Linear(num_fc1, num_classes)\n",
    "\n",
    "    def forward(self,X):\n",
    "        \n",
    "        # Convolution & Pool Layers\n",
    "        X = F.relu(self.conv1(X)); \n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = F.relu(self.conv3(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = F.relu(self.conv4(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "\n",
    "        X = X.view(-1, self.num_flatten)\n",
    "        \n",
    "        X = F.relu(self.fc1(X))\n",
    "        X=F.dropout(X, self.dropout_rate)\n",
    "        X = self.fc2(X)\n",
    "        return F.log_softmax(X, dim=1)\n",
    "    \n",
    "def findConv2dOutShape(hin,win,conv,pool=2):\n",
    "    # get conv arguments\n",
    "    kernel_size=conv.kernel_size\n",
    "    stride=conv.stride\n",
    "    padding=conv.padding\n",
    "    dilation=conv.dilation\n",
    "\n",
    "    hout=np.floor((hin+2*padding[0]-dilation[0]*(kernel_size[0]-1)-1)/stride[0]+1)\n",
    "    wout=np.floor((win+2*padding[1]-dilation[1]*(kernel_size[1]-1)-1)/stride[1]+1)\n",
    "\n",
    "    if pool:\n",
    "        hout/=pool\n",
    "        wout/=pool\n",
    "    return int(hout),int(wout)\n",
    "\n",
    "# Neural Network Predefined Parameters\n",
    "params_model={\n",
    "        \"shape_in\": (3,64,64), \n",
    "        \"initial_filters\": 8,    \n",
    "        \"num_fc1\": 100,\n",
    "        \"dropout_rate\": 0.25,\n",
    "        \"num_classes\": 2}\n",
    "\n",
    "# Create instantiation of Network class\n",
    "cnn_model = Network(params_model)\n",
    "\n",
    "# define computation hardware approach (GPU/CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = cnn_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71de257",
   "metadata": {},
   "source": [
    "## What TAs do\n",
    "In this way, TAs can get the test result by only replacing the “test_dataset_path”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16788d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_path = 'path_to_test_set'\n",
    "test(model, test_dataset_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
