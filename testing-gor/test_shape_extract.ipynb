{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "#import library\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_loader(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        # Get Image File Names\n",
    "        real = os.path.join(data_dir, '0_real')  # directory of files\n",
    "        fake = os.path.join(data_dir, '1_fake')\n",
    "\n",
    "        file_names_real = os.listdir(real)  # get list of images in that directory\n",
    "        self.full_filenames_real = [os.path.join(real, f) for f in file_names_real]  # get the full path to images\n",
    "        file_names_fake = os.listdir(fake)  # get list of images in that directory\n",
    "        self.full_filenames_fake = [os.path.join(fake, f) for f in file_names_fake]  # get the full path to images\n",
    "        self.full_filenames = self.full_filenames_real + self.full_filenames_fake\n",
    "\n",
    "        self.labels_real = [0 for filename in file_names_real]\n",
    "        self.labels_fake = [1 for filename in file_names_fake]\n",
    "        self.labels = self.labels_real + self.labels_fake\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "                                            transforms.RandomResizedCrop(size=(64, 64)),\n",
    "                                            # transforms.RandomHorizontalFlip(),\n",
    "                                            transforms.ToTensor(),\n",
    "                                            ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.full_filenames_real) + len(self.full_filenames_fake) # size of dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # open image, apply transforms and return with label\n",
    "        image = Image.open(self.full_filenames[idx])  # Open Image with PIL\n",
    "        # image = self.transform(image) # Apply Specific Transformation to Image\n",
    "        return image, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_path = os.getcwd().replace(\"nn\", \"\") + \"\\\\AIGC-Detection-Dataset\\\\train\"\n",
    "test_dataset = data_loader(test_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=640x426 at 0x16B19E57190>, 0)\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
